{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (60000, 28, 28)\n",
      "Train Labels Shape: (60000,)\n",
      "Train Images DataType: uint8\n",
      "Test Images Shape: (10000, 28, 28)\n",
      "Test Labels Shape: (10000,)\n",
      "Test Images DataType: uint8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mnist\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "num_train_images = len(train_labels)\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "num_test_images = len(test_images)\n",
    "\n",
    "# print the data dimensions\n",
    "print(\"Train Images Shape: \"+str(train_images.shape))\n",
    "print(\"Train Labels Shape: \"+str(train_labels.shape))\n",
    "print('Train Images DataType: '+str(train_images.dtype))\n",
    "print(\"Test Images Shape: \"+str(test_images.shape))\n",
    "print(\"Test Labels Shape: \"+str(test_labels.shape))\n",
    "print('Test Images DataType: '+str(test_images.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "  return np.max((0,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "  \n",
    "  def __init__(self, numInputs, numNodes):\n",
    "    self.numInputs = numInputs\n",
    "    self.numNodes = numNodes\n",
    "    self.weights = np.random.normal(0.0, 0.05, size=(numNodes, numInputs))\n",
    "    self.biases = np.zeros(numNodes)\n",
    "\n",
    "  def apply(self, inputs):\n",
    "    if (len(inputs) != self.numInputs):\n",
    "      print(\"WARNING: Inputs to layer wrong size for the layer.\")\n",
    "      output = np.zeros(self.numNodes)\n",
    "      return output\n",
    "    output = np.zeros(self.numNodes)\n",
    "    h = np.matmul(self.weights, inputs) + self.biases\n",
    "    for i in range(self.numNodes):\n",
    "      output[i] = ReLU(h[i])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(inputs):\n",
    "  outputs = np.exp(inputs)/np.sum(np.exp(inputs))\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = FullyConnectedLayer(28*28,30)\n",
    "layer2 = FullyConnectedLayer(30,10)\n",
    "layerFinal = softmax\n",
    "'''\n",
    "layer1 = FullyConnectedLayer(28*28, 250)\n",
    "layer2 = FullyConnectedLayer(250, 200)\n",
    "layer3 = FullyConnectedLayer(200, 150)\n",
    "layer4 = FullyConnectedLayer(150, 100)\n",
    "layer5 = FullyConnectedLayer(100, 50)\n",
    "layer6 = FullyConnectedLayer(50, 10)\n",
    "layerFinal = softmax\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_dh2(network,obs,y):\n",
    "  yHat = network.apply(obs)\n",
    "  numh2i = network.layer2.numNodes \n",
    "  dldh2 = np.zeros(numh2i)\n",
    "  for i in range(numh2i):\n",
    "    dldh2[i] = yHat[i] - y[i]\n",
    "  return dldh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dL_dW2(network,obs,y):\n",
    "  dldh2 = dl_dh2(network,obs,y)\n",
    "  numh2i = network.layer2.numNodes \n",
    "  numh1i = network.layer1.numNodes \n",
    "  dLdW2 = np.zeros((numh2i,numh1i))\n",
    "  for i in range(numh2i):\n",
    "    for j in range(numh1i):\n",
    "      if (network.out2[i] == 0):\n",
    "        dLdW2[i,j] = 0\n",
    "      else:\n",
    "        dLdW2[i,j] = dldh2[i]*network.out1[j]\n",
    "  return dLdW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dL_db2(network,obs,y):\n",
    "  dldh2 = dl_dh2(network,obs,y)\n",
    "  numh2i = network.layer2.numNodes\n",
    "  dLdb2 = np.zeros(numh2i)\n",
    "  for i in range(numh2i):\n",
    "    if (network.out2[i] == 0):\n",
    "      dLdb2[i] = 0\n",
    "    else:\n",
    "      dLdb2[i] = dldh2[i]\n",
    "  return dLdb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dL_dW1(network,obs,y):\n",
    "  dldh2 = dl_dh2(network,obs,y)\n",
    "  numh2i = network.layer2.numNodes \n",
    "  numh1i = network.layer1.numNodes \n",
    "  numInputs = network.layer1.numInputs\n",
    "  dLdW1 = np.zeros((numh1i,numInputs))\n",
    "  for i in range(numh1i):\n",
    "    for k in range(numh2i):\n",
    "      if not (network.out2[k] == 0) or (network.out1[i] == 0):\n",
    "        for j in range(numInputs):\n",
    "          dLdW1[i,j] = dLdW1[i,j] + dldh2[k]*network.layer2.weights[k,i]*obs[j]\n",
    "  return dLdW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dL_db1(network,obs,y):\n",
    "  dldh2 = dl_dh2(network,obs,y)\n",
    "  numh2i = network.layer2.numNodes \n",
    "  numh1i = network.layer1.numNodes\n",
    "  dLdb1 = np.zeros((numh1i))\n",
    "  for i in range(numh1i):\n",
    "    for k in range(numh2i):\n",
    "      if not (network.out2[k] == 0) or (network.out1[i] == 0):\n",
    "        dLdb1[i] = dLdb1[i] + dldh2[k]*network.layer2.weights[k,i]\n",
    "  return dLdb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network2layers():\n",
    "  \n",
    "  def __init__(self, layer1, layer2, layerFinal):\n",
    "    self.layer1 = layer1\n",
    "    self.layer2 = layer2\n",
    "    self.layerFinal = layerFinal\n",
    "  \n",
    "  def apply(self, inputs):\n",
    "    self.inputs = inputs\n",
    "    self.out1 = self.layer1.apply(self.inputs)\n",
    "    self.out2 = self.layer2.apply(self.out1)\n",
    "    self.outFinal = self.layerFinal(self.out2)\n",
    "    return self.outFinal\n",
    "\n",
    "  def train(self, obs, y, alpha):\n",
    "    self.layer1.weights = self.layer1.weights - alpha*dL_dW1(network,obs,y)\n",
    "    self.layer1.biases = self.layer1.biases - alpha*dL_db1(network,obs,y)\n",
    "    self.layer2.weights = self.layer2.weights - alpha*dL_dW2(network,obs,y)\n",
    "    self.layer2.biases = self.layer2.biases - alpha*dL_db2(network,obs,y)\n",
    "  \n",
    "  def trainMiniBatch(self, obs_list, y_list, alpha):\n",
    "    self.batch_size = len(y_list)\n",
    "    deltaL_dW1 = 0\n",
    "    deltaL_db1 = 0\n",
    "    deltaL_dW2 = 0\n",
    "    deltaL_db2 = 0\n",
    "    for i in range(self.batch_size):\n",
    "      y = y_list[i]\n",
    "      obs = obs_list[i]\n",
    "      deltaL_dW1 = deltaL_dW1 + dL_dW1(network,obs,y)\n",
    "      deltaL_db1 = deltaL_db1 + dL_db1(network,obs,y)\n",
    "      deltaL_dW2 = deltaL_dW2 + dL_dW2(network,obs,y)\n",
    "      deltaL_db2 = deltaL_db2 + dL_db2(network,obs,y)\n",
    "    self.layer1.weights = self.layer1.weights -  alpha*deltaL_dW1/self.batch_size\n",
    "    self.layer1.biases = self.layer1.biases - alpha*deltaL_db1/self.batch_size\n",
    "    self.layer2.weights = self.layer2.weights - alpha*deltaL_dW2/self.batch_size\n",
    "    self.layer2.biases = self.layer2.biases - alpha*deltaL_db2/self.batch_size\n",
    "\n",
    "network = network2layers(layer1, layer2, layerFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(y,yHat):\n",
    "  L = 0\n",
    "  m = len(y)\n",
    "  for i in range(m):\n",
    "    yHat[i] = max(10**(-10),yHat[i])\n",
    "    L = L + y[i]*np.log(yHat[i])\n",
    "  return -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "num_iters = 20\n",
    "batch_size = 20\n",
    "for i in range(num_iters):\n",
    "  batch_idx = np.random.randint(0, high=num_train_images, size=batch_size)\n",
    "  y_list = []\n",
    "  obs_list = []\n",
    "  for idx in batch_idx:\n",
    "    y = np.zeros(10)\n",
    "    y[train_labels[idx]] = 1\n",
    "    y_list.append(y)\n",
    "    obs = train_images[idx,:,:].flatten()/255.  \n",
    "    obs_list.append(obs)\n",
    "  network.trainMiniBatch(obs_list, y_list, 1)\n",
    "  \n",
    "  idx = random.randrange(num_test_images)\n",
    "  y = np.zeros(10)\n",
    "  y[test_labels[idx]] = 1\n",
    "  obs = test_images[idx,:,:].flatten()/255.  \n",
    "  yhat = network.apply(obs)\n",
    "  L.append(Loss(y,yhat))\n",
    "  print('Completed '+str(i)+' of '+str(num_iters), end = '')\n",
    "  print(' -- Truth: '+str(test_labels[idx])+' | Predicted Prob: '+str(yhat[test_labels[idx]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
